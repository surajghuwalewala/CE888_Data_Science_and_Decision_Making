{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMzBewNLNvuhOahwAFVAwt0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajghuwalewala/CE888_Data_Science_and_Decision_Making/blob/master/Lab_5/my_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hvgnA8S3lwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L57O5Ed_4AcM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80177686-b6cd-400c-dc77-c5db7af31b5b"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/albanda/CE888/master/lab5-recommender/jester-data-1.csv\")\n",
        "df.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24982, 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwS0hOLw6tt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be7BfrHT4dZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace(orig, percentage=0.1):\n",
        "  \"\"\"\n",
        "  Replaces 'percentage'% of the original values in 'orig' with 99's\n",
        "  :param orig: original data array\n",
        "  :param percentage: percentage of values to replace (0<percentage<1)\n",
        "  \"\"\"\n",
        "  new_data = orig.copy()\n",
        "  rated = np.where(orig!=99)\n",
        "  n_rated = len(rated[0])\n",
        "  idx = np.random.choice(n_rated, size=int(percentage*n_rated), replace=False)\n",
        "  new_data[rated[0][idx], rated[1][idx]] = 99\n",
        "  return new_data, (rated[0][idx], rated[1][idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPqKA9eS6ZcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_set, idx = replace(df.values, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc_dt_ox683M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def latentFactorModelling(data, n_latent_factors = 2, alpha = 0.0001, iterations=300):\n",
        "\n",
        "  user_ratings = data.values\n",
        "  # Initialise as random values\n",
        "  latent_user_preferences = np.random.random((user_ratings.shape[0], n_latent_factors))\n",
        "  latent_item_features = np.random.random((user_ratings.shape[1], n_latent_factors))\n",
        "  \n",
        "  \n",
        "  def predict_rating(user_id, item_id):\n",
        "    \"\"\" Predict a rating given a user_id and an item_id.\n",
        "    \"\"\"\n",
        "    user_preference = latent_user_preferences[user_id]\n",
        "    item_preference = latent_item_features[item_id]\n",
        "    return user_preference.dot(item_preference)\n",
        "\n",
        "\n",
        "  def train(user_id, item_id, rating, alpha = alpha):\n",
        "      \n",
        "    #print item_id\n",
        "    prediction_rating = predict_rating(user_id, item_id)\n",
        "    err =  prediction_rating - rating\n",
        "    #print err\n",
        "    user_pref_values = latent_user_preferences[user_id][:]\n",
        "    latent_user_preferences[user_id] -= alpha * err * latent_item_features[item_id]\n",
        "    latent_item_features[item_id] -= alpha * err * user_pref_values\n",
        "    return err\n",
        "      \n",
        "\n",
        "  def sgd(iterations=iterations):\n",
        "    \"\"\" Iterate over all users and all items and train for \n",
        "        a certain number of iterations\n",
        "    \"\"\"\n",
        "    for iteration in range(iterations):\n",
        "        error = []\n",
        "        for user_id in range(latent_user_preferences.shape[0]):\n",
        "            for item_id in range(latent_item_features.shape[0]):\n",
        "                rating = user_ratings[user_id][item_id]\n",
        "                if (rating != 99.0):\n",
        "                    err = train(user_id, item_id, rating)\n",
        "                    error.append(err)\n",
        "        mse = (np.array(error) ** 2).mean()   \n",
        "        if (iteration % 10) == 0:\n",
        "            print(mse)\n",
        "\n",
        "  sgd(iterations)\n",
        "\n",
        "  np.save(\"latent_factors_{}_iterations.npy\".format(iterations), [latent_user_preferences, latent_item_features] )\n",
        "\n",
        "  return latent_user_preferences, latent_item_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knwqC4v3Qsy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = [1,2]\n",
        "y = [2,3]\n",
        "np.save(\"text.npy\", [x, y] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGclr6XZ-OXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "90c3da6e-7e31-4e8b-d885-586e766f7301"
      },
      "source": [
        "latent_user_preferences, latent_item_features = latentFactorModelling(df, iterations=50)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58.12517708133608\n",
            "24.55491406393803\n",
            "20.208689381922422\n",
            "18.07757880081991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-24018da2100e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlatent_user_preferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_item_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatentFactorModelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-742920c27919>\u001b[0m in \u001b[0;36mlatentFactorModelling\u001b[0;34m(data, n_latent_factors, alpha, iterations)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlatent_user_preferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_item_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-742920c27919>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(iterations)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_user_preferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_item_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrating\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m99.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdFgwe9q6_rA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "15dc499b-422f-4136-b99b-7c374c8df059"
      },
      "source": [
        "## Train predictions\n",
        "predictions = latent_user_preferences.dot(latent_item_features.T)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fae170691646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_user_preferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_item_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'latent_user_preferences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIVHvH95H4wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "e47001e9-b529-4e2f-ef73-e5b9f04b51b7"
      },
      "source": [
        "## Validation predictions\n",
        "\n",
        "val_pred = val_set.copy()\n",
        "for user_id in range(latent_user_preferences.shape[0]):\n",
        "  for item_id in range(latent_item_features.shape[0]):\n",
        "    rating = val_set[user_id][item_id]\n",
        "    if (rating == 99.0):\n",
        "      prediction_rating = predictions[user_id][item_id]\n",
        "      val_pred[user_id][item_id] = prediction_rating\n",
        "    \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4bffb2a15278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_user_preferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_item_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'latent_user_preferences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X61ocS6H41M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Test Pred\n",
        "test_pred = df.values.copy()\n",
        "for user_id in range(latent_user_preferences.shape[0]):\n",
        "  for item_id in range(latent_item_features.shape[0]):\n",
        "    rating = val_set[user_id][item_id]\n",
        "    if (rating == 99.0):\n",
        "      prediction_rating = predictions[user_id][item_id]\n",
        "      test_pred[user_id][item_id] = prediction_rating"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ZOShCwH4zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "values = [zip(df.values[i], predictions[i], val_pred[i], test_pred[i]) for i in range(predictions.shape[0])]\n",
        "comparison_data = pd.DataFrame(values)\n",
        "comparison_data.columns = df.columns\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTgce-oVH4t2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}