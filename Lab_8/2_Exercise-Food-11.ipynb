{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNSY2x+3leawDAn+2JrRY30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajghuwalewala/CE888_Data_Science_and_Decision_Making/blob/master/Lab_8/1_Exercise-Food-11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zYwKD2ZLwDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ae562941-d435-41e9-d14d-8ce7786d5a20"
      },
      "source": [
        "## Download the VGG16 file from Github\n",
        "! curl https://raw.githubusercontent.com/surajghuwalewala/CE888_Data_Science_and_Decision_Making/master/Lab_8/vgg16.py --output vgg16.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  8740  100  8740    0     0   193k      0 --:--:-- --:--:-- --:--:--  193k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfGovcwFNWB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "fae62458-fc80-4bae-9ebc-08d7a26b70d6"
      },
      "source": [
        "!pip install tensorflow==1.3.0\n",
        "!pip install keras==2.0.7"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/7c/9f/57e1404fc9345759e4a732c4ab48ab4dd78fd1e60ee1270442b8850fa75f/tensorflow-1.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (1.17.5)\n",
            "Collecting tensorflow-tensorboard<0.2.0,>=0.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/31/bb4111c3141d22bd7b2b553a26aa0c1863c86cb723919e5bd7847b3de4fc/tensorflow_tensorboard-0.1.8-py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.3.0) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3.0) (1.0.0)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=be9adab4f00db4542d3c66ab0c81f452bce38ed93facc29bb36dcf0b60b36cbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: html5lib, bleach, tensorflow-tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorflow-1.3.0 tensorflow-tensorboard-0.1.8\n",
            "Requirement already satisfied: keras==2.0.7 in /usr/local/lib/python3.6/dist-packages (2.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (3.13)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.7) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.7) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO_I4MuhGb0G",
        "colab_type": "code",
        "outputId": "35325d07-ec8e-4805-c002-9f97c585e090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"surajghuwalewala\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"c14ff4f2803c1ffb349c4b9e1a57020b\" # key from the json file\n",
        "DOWNLOAD_DATA = True\n",
        "\n",
        "if DOWNLOAD_DATA:\n",
        "    !kaggle datasets download -d trolukovich/food11-image-dataset # api copied from kaggle\n",
        "    !unzip -q /content/food11-image-dataset.zip   ## '-q' unzips without verbose output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading food11-image-dataset.zip to /content\n",
            "100% 1.08G/1.08G [00:16<00:00, 104MB/s] \n",
            "100% 1.08G/1.08G [00:16<00:00, 71.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfsi064YIVdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/content/training/'\n",
        "test_dir = '/content/evaluation/'\n",
        "val_dir = '/content/validation/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yNAMSczGwvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_generator = datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(IMG_SIZE, IMG_SIZE), \n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(val_dir,\n",
        "                                                        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                                        batch_size=100,\n",
        "                                                        class_mode='categorical')\n",
        "\n",
        "test_generator = datagen.flow_from_directory(test_dir,\n",
        "                                                    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='categorical')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZhxj1DTKXiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras import layers\n",
        "# from keras import models\n",
        "# from keras.layers import BatchNormalization, Activation\n",
        "\n",
        "\n",
        "\n",
        "# model = models.Sequential()\n",
        "# model.add(layers.Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
        "# model.add(layers.Dropout(0.25))\n",
        "\n",
        "# model.add(layers.Conv2D(64, (3, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
        "# model.add(layers.Dropout(0.25))\n",
        "\n",
        "# model.add(layers.Conv2D(256, (3, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
        "# model.add(layers.Dropout(0.25))\n",
        "\n",
        "\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(512, activation='relu'))\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "# model.add(layers.Dense(11, activation='softmax'))\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_To7l9mbM9Do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import merge, Input\n",
        "from vgg16 import VGG16\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "image_input = Input(shape=(224, 224, 3)) # shape of a single image\n",
        "\n",
        "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet') # load VGG-16 model with 'top = true'\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ3sKSdxSsY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_layer = model.get_layer('fc2').output\n",
        "#x= Flatten(name='flatten')(last_layer)\n",
        "out = Dense(11, activation='softmax', name='output')(last_layer)  ## 11 classes\n",
        "custom_vgg_model = Model(image_input, out)\n",
        "custom_vgg_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgJs4stXSsTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in custom_vgg_model.layers[:-1]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "custom_vgg_model.layers[3].trainable\n",
        "custom_vgg_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6KO5E4sNcIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_vgg_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWHu1t8CMvz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = custom_vgg_model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=30,\n",
        "                              epochs=5,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tumFA08cNX1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqpoA7XQgGiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}